# Voice Document Intelligence System

A production-ready AI-powered voice-enabled document intelligence platform with advanced contextual embeddings and real-time voice interaction.

![System Status](https://img.shields.io/badge/status-active-success)
![Python](https://img.shields.io/badge/python-3.11+-blue)
![Node](https://img.shields.io/badge/node-18+-green)
![TypeScript](https://img.shields.io/badge/typescript-5.0+-blue)
![License](https://img.shields.io/badge/license-MIT-blue)

## ğŸŒŸ Features

### ğŸ“„ Intelligent Document Processing
- **Multi-format Support**: PDF, DOCX, DOC, TXT
- **Smart Chunking**: Preserves semantic boundaries and document structure
- **3-Level Contextual Embeddings**:
  - **Local Context**: Surrounding chunks (50% weight)
  - **Document Context**: Document structure and themes (30% weight)
  - **Global Context**: Cross-document relationships (20% weight)
- **Rich Metadata Extraction**: Named entities, keywords, section hierarchy

### ğŸ¤ Voice Interface
- **Ultra-Low Latency**: Target <200ms end-to-end
- **Advanced Voice Stack**:
  - Speech-to-Text: Deepgram Nova-3
  - Text-to-Speech: Cartesia Sonic
  - Infrastructure: LiveKit WebRTC
- **Natural Conversations**: Context-aware dialogue with documents

### ğŸ’¬ Chat Interface
- **Contextual Q&A**: Ask questions in natural language
- **Source Attribution**: See which chunks informed each answer
- **Multi-level Search**: Local, document, or global context
- **Conversation Memory**: Maintains dialogue context

### ğŸ¤– Multi-Agent Architecture
Five specialized AI agents working together:
1. **Document Agent**: Intelligent processing and chunking
2. **Voice Agent**: Real-time speech interaction
3. **Query Agent**: Intent recognition and enhancement
4. **Context Agent**: Multi-level contextual search
5. **Analytics Agent**: Usage patterns and insights

### ğŸ“Š Analytics Dashboard
- Document processing statistics
- Performance metrics (latency, success rates)
- System health monitoring
- Usage analytics

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Frontend (Next.js + React)                â”‚
â”‚              TypeScript â€¢ Tailwind â€¢ LiveKit                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                        â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚           â”‚           â”‚
            â”‚ HTTP/REST â”‚ WebSocket â”‚ LiveKit/WebRTC
            â”‚           â”‚           â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                Backend API (FastAPI)                         â”‚
â”‚         Python â€¢ Async â€¢ Multi-Agent System                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚                                       â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”                       â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”
    â”‚ Infrastructure â”‚                       â”‚  AI Services â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜                       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
            â”‚                                       â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ â€¢ PostgreSQL           â”‚              â”‚ â€¢ OpenAI GPT-4      â”‚
    â”‚ â€¢ Redis                â”‚              â”‚ â€¢ Deepgram Nova-3   â”‚
    â”‚ â€¢ Qdrant (Vectors)     â”‚              â”‚ â€¢ Cartesia Sonic    â”‚
    â”‚ â€¢ LiveKit Server       â”‚              â”‚ â€¢ Sentence Trans.   â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.11+**
- **Node.js 18+**
- **Docker & Docker Compose**
- **API Keys**:
  - OpenAI API key (required)
  - Deepgram API key (for voice)
  - Cartesia API key (for voice)

### Installation

```bash
# Clone the repository
git clone <your-repo-url>
cd voice-doc-intelligence

# Run the setup script
./start-dev.sh

# Follow the on-screen instructions
```

For detailed setup instructions, see [QUICKSTART.md](QUICKSTART.md)

### Manual Setup

1. **Start Infrastructure**
   ```bash
   cd infrastructure/local
   docker-compose up -d
   ```

2. **Start Backend**
   ```bash
   cd apps/api
   python3 -m venv venv
   source venv/bin/activate
   pip install -e ../..
   python main.py
   ```

3. **Start Frontend**
   ```bash
   cd apps/web
   npm install
   npm run dev
   ```

4. **Access the Application**
   - Frontend: http://localhost:3000
   - Backend API: http://localhost:8000
   - API Docs: http://localhost:8000/docs

## ğŸ“ Project Structure

```
voice-doc-intelligence/
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ api/                      # FastAPI backend
â”‚   â”‚   â”œâ”€â”€ main.py              # Main application
â”‚   â”‚   â”œâ”€â”€ core/                # Configuration & database
â”‚   â”‚   â”œâ”€â”€ models/              # Data models
â”‚   â”‚   â”œâ”€â”€ routers/             # API routes
â”‚   â”‚   â””â”€â”€ services/            # Business logic
â”‚   â”‚       â”œâ”€â”€ agents/          # Multi-agent system
â”‚   â”‚       â”œâ”€â”€ document/        # Document processing
â”‚   â”‚       â”œâ”€â”€ voice/           # Voice services
â”‚   â”‚       â””â”€â”€ rag/            # RAG implementation
â”‚   â”œâ”€â”€ web/                     # Next.js frontend
â”‚   â”‚   â”œâ”€â”€ app/                # Next.js app directory
â”‚   â”‚   â”œâ”€â”€ components/         # React components
â”‚   â”‚   â”œâ”€â”€ lib/                # Utilities & API client
â”‚   â”‚   â””â”€â”€ types/              # TypeScript types
â”‚   â””â”€â”€ workers/                # Background workers
â”‚       â””â”€â”€ enhanced_voice_agent_worker.py
â”œâ”€â”€ infrastructure/
â”‚   â””â”€â”€ local/
â”‚       â”œâ”€â”€ docker-compose.yml  # Local development stack
â”‚       â””â”€â”€ livekit.yaml        # LiveKit configuration
â”œâ”€â”€ data/                       # Data storage (local mode)
â”œâ”€â”€ .env                        # Environment variables
â”œâ”€â”€ pyproject.toml             # Python dependencies
â”œâ”€â”€ start-dev.sh               # Development startup script
â”œâ”€â”€ QUICKSTART.md              # Detailed setup guide
â””â”€â”€ README.md                  # This file
```

## ğŸ”§ Configuration

### Environment Variables

Create a `.env` file in the project root:

```env
# AI Services
OPENAI_API_KEY=your_key_here
DEEPGRAM_API_KEY=your_key_here
CARTESIA_API_KEY=your_key_here

# Database
POSTGRES_USER=voicedoc
POSTGRES_PASSWORD=voicedoc123
POSTGRES_DB=voice_doc_intel

# Redis
REDIS_PASSWORD=voicedoc123

# Application
APP_ENV=development
API_PORT=8000
STORAGE_TYPE=local
```

See [QUICKSTART.md](QUICKSTART.md) for complete configuration details.

## ğŸ“š Usage

### 1. Upload Documents

```bash
# Via API
curl -X POST http://localhost:8000/api/v1/documents/upload \
  -F "file=@document.pdf" \
  -F "use_enhanced=true"

# Via Web UI
# Go to http://localhost:3000 â†’ Documents tab â†’ Drag & drop
```

### 2. Query Documents

```bash
# Via API
curl -X POST http://localhost:8000/api/v1/query \
  -H "Content-Type: application/json" \
  -d '{
    "query": "What are the main topics?",
    "context_level": "document",
    "use_enhanced": true
  }'

# Via Web UI
# Go to Chat tab â†’ Type your question
```

### 3. Use Voice Interface

1. Go to Voice tab in the web UI
2. Click "Connect to Voice Assistant"
3. Allow microphone permissions
4. Speak your question naturally

## ğŸ¯ Key Technologies

### Backend
- **FastAPI**: Modern async Python web framework
- **SQLAlchemy**: Database ORM
- **Qdrant**: Vector database for embeddings
- **Redis**: Caching and real-time features
- **OpenAI**: GPT-4 for LLM capabilities
- **CrewAI**: Multi-agent orchestration
- **spaCy**: NLP and entity extraction
- **sentence-transformers**: Local embeddings

### Frontend
- **Next.js 14**: React framework with App Router
- **TypeScript**: Type-safe development
- **Tailwind CSS**: Utility-first styling
- **LiveKit React**: Voice/video components
- **Axios**: HTTP client
- **Recharts**: Analytics visualization

### Infrastructure
- **Docker**: Containerization
- **PostgreSQL**: Relational database
- **Redis Stack**: In-memory database
- **Qdrant**: Vector similarity search
- **LiveKit**: Real-time communication
- **MinIO**: S3-compatible object storage

## ğŸ“ˆ Performance

- **Document Processing**: <5s for typical PDF
- **Query Latency**: <2s end-to-end
- **Voice Pipeline**:
  - STT: <150ms (Deepgram)
  - LLM: <800ms (GPT-4)
  - TTS: <100ms (Cartesia)
  - Target Total: <200ms

## ğŸ§ª Testing

```bash
# Backend tests
cd apps/api
pytest

# Frontend tests
cd apps/web
npm test

# End-to-end tests
npm run test:e2e
```

## ğŸ“– Documentation

- [Quick Start Guide](QUICKSTART.md) - Complete setup instructions
- [Frontend Setup](apps/web/SETUP.md) - Frontend-specific guide
- [Frontend README](apps/web/README.md) - Frontend documentation
- [Agent Documentation](apps/api/services/agents/README.md) - Multi-agent system

## ğŸ” API Documentation

Interactive API documentation is available at:
- Swagger UI: http://localhost:8000/docs
- ReDoc: http://localhost:8000/redoc

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ğŸ› Troubleshooting

### Common Issues

**Port Already in Use**
```bash
# Kill process on port 8000 (backend)
lsof -ti:8000 | xargs kill -9

# Kill process on port 3000 (frontend)
lsof -ti:3000 | xargs kill -9
```

**Docker Services Won't Start**
```bash
# Reset Docker services
cd infrastructure/local
docker-compose down -v
docker-compose up -d
```

**Voice Not Working**
- Verify LiveKit is running: `docker-compose ps livekit`
- Check microphone permissions in browser
- Ensure API keys are set correctly

See [QUICKSTART.md](QUICKSTART.md) for more troubleshooting tips.

## ğŸ“Š Monitoring

Access monitoring dashboards:
- **Prometheus**: http://localhost:9090
- **Grafana**: http://localhost:3000
- **Redis Insight**: http://localhost:8001
- **Qdrant Dashboard**: http://localhost:6333/dashboard

## ğŸ”’ Security

- API keys stored in environment variables
- CORS configured for local development
- File upload validation and size limits
- SQL injection prevention via ORM
- XSS protection in frontend

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ™ Acknowledgments

- **OpenAI** - GPT-4 and embeddings
- **Deepgram** - Speech-to-text
- **Cartesia** - Text-to-speech
- **LiveKit** - Real-time communication infrastructure
- **CrewAI** - Multi-agent framework
- **Qdrant** - Vector database

## ğŸ“§ Support

For issues and questions:
1. Check [QUICKSTART.md](QUICKSTART.md) for setup help
2. Review existing GitHub issues
3. Create a new issue with detailed information

## ğŸ—ºï¸ Roadmap

- [ ] Multi-language support
- [ ] Advanced analytics with ML insights
- [ ] Mobile application
- [ ] Collaboration features
- [ ] Knowledge graph visualization
- [ ] Custom agent creation framework
- [ ] Enterprise SSO integration
- [ ] Advanced security features

---

**Built with â¤ï¸ for intelligent document interaction**

*Voice Document Intelligence v2.0*
